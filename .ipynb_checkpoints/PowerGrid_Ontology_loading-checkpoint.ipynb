{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a42461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from neo4j import GraphDatabase\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ce88a",
   "metadata": {},
   "source": [
    "## Load Json file to Create nodes and relations in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd7a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"neo4jkngbq\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def get_all_json_paths(folder_path):\n",
    "  \"\"\"\n",
    "  Retrieves all file paths ending with the '.json' extension within a folder and its subfolders using glob.\n",
    "\n",
    "  Args:\n",
    "      folder_path (str): The path to the folder where the search starts.\n",
    "\n",
    "  Returns:\n",
    "      list: A list containing absolute paths to all JSON files found.\n",
    "  \"\"\"\n",
    "\n",
    "  # Construct a pattern to match all JSON files recursively\n",
    "  json_pattern = os.path.join(folder_path, \"**/*.json\")\n",
    "\n",
    "  # Use glob.glob to find all matching files\n",
    "  json_paths = glob.glob(json_pattern, recursive=True)\n",
    "\n",
    "  return json_paths\n",
    "\n",
    "\"\"\"\n",
    "    This methods loads the json data from the given file path and return the json data as dictionary\n",
    "\"\"\"\n",
    "def load_json_data_from_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = f.read()\n",
    "        json_data = json.loads(data)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe152d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066ae493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfile_path = \"./Ontology/Core/Bay.json\"\\ndata = load_json_data_from_file(file_path)\\n\\nwith driver.session() as session:\\n    session.write_transaction(create_nodes, data)\\n                \\n    \\n    \\ndriver.close() \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def create_interface_node(tx, interface_data):\n",
    "    unique_id = interface_data.get(\"id\")\n",
    "    tx.run(\"MERGE (n:Interface {id:$unique_id}) SET n=$data\", data=interface_data, unique_id=unique_id)\n",
    "    \n",
    "def create_property_node(tx, property_data):\n",
    "    unique_id = property_data.get(\"id\")\n",
    "    tx.run(\"MERGE (n:Property {id:$unique_id}) SET n=$data\", data = property_data, unique_id=unique_id)\n",
    "    \n",
    "def create_nodes(tx,data):\n",
    "    interface_node_data = {}\n",
    "    interface_node_data[\"id\"] = data.get(\"@id\")\n",
    "    interface_node_data[\"type\"] = data.get(\"@type\")\n",
    "    interface_node_data[\"name\"] = data.get(\"displayName\")\n",
    "    interface_node_data[\"description\"] = data.get(\"description\")\n",
    "    interface_node_data[\"comment\"] = data.get(\"comment\")\n",
    "    \n",
    "    create_interface_node(tx, interface_node_data)\n",
    "    \n",
    "    if(None != data.get('extends')):\n",
    "        super_id = data.get('extends')\n",
    "        tx.run(\"MERGE (n:Interface {id:$super_id}) ON CREATE SET n = {id:$super_id}\", super_id=super_id)\n",
    "        interface_id = interface_node_data[\"id\"]\n",
    "        tx.run(\"MATCH (parent:Interface {id:$super_id}), (child:Interface {id:$interface_id}) CREATE (parent)-[:has_child]->(child)\", super_id=super_id, interface_id=interface_id)\n",
    "    \n",
    "    if(None != data.get('contents') or (len(data.get('contents'))>0)):\n",
    "        for content in data.get('contents'):\n",
    "            if(\"Property\" == content.get(\"@type\")):\n",
    "                property_node_data = {}\n",
    "                property_node_data['id'] = content.get('name')\n",
    "                property_node_data['name'] = content.get('name')\n",
    "                property_node_data['type'] = content.get('@type')\n",
    "                property_node_data['comment'] = content.get('comment')\n",
    "                if(isinstance(content.get('schema'), dict)):\n",
    "                    property_node_data['schema'] = \"enum\"\n",
    "                else:\n",
    "                    property_node_data['schema'] = content.get('schema')\n",
    "                \n",
    "                create_property_node(tx, property_node_data)\n",
    "                \n",
    "                interface_id = interface_node_data[\"id\"]\n",
    "                property_id = property_node_data['id']\n",
    "                \n",
    "                #query = \"\"\" MATCH (interface:Interface {{id:$interface_id})\n",
    "                 #           MATCH (property:Property {{id:$property_id}})\n",
    "                  #          CREATE (interface)-[:has_property]->(property)\n",
    "                   #     \"\"\"\n",
    "            \n",
    "                tx.run(\"MATCH (interface:Interface {id:$interface_id}), (property:Property {id:$property_id}) CREATE (interface)-[:has_property]->(property)\", interface_id=interface_id, property_id=property_id)\n",
    "                       \n",
    "            elif(\"Relationship\" == content.get(\"@type\")):\n",
    "                relation_node_data = {}\n",
    "                relation_node_data['id'] = content.get('target')\n",
    "                relation_node_data['name'] = content.get('displayName')\n",
    "                relation_node_data['comment'] = content.get('comment')\n",
    "                relation_node_data['@type'] = \"Interface\"\n",
    "                create_interface_node(tx, relation_node_data)\n",
    "                \n",
    "                \n",
    "                interface_id = interface_node_data[\"id\"]\n",
    "                relation_node_id = relation_node_data['id']\n",
    "                \n",
    "                tx.run(\"MATCH (interface:Interface {id:$interface_id}), (property:Interface {id:$relation_node_id}) CREATE (interface)-[:conected_to]->(property)\",interface_id=interface_id, relation_node_id=relation_node_id)\n",
    "              \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735179b",
   "metadata": {},
   "source": [
    "# Load the Digital Twin Ontology to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503cd0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/3357173862.py:8: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(create_nodes, data)\n",
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/3357173862.py:7: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session() as session:\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./Ontology\" \n",
    "json_file_paths = get_all_json_paths(folder_path)\n",
    "\n",
    "for each_json in json_file_paths:\n",
    "    data = load_json_data_from_file(each_json)\n",
    "\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(create_nodes, data)\n",
    "        \n",
    "    driver.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99c40a",
   "metadata": {},
   "source": [
    "# DELETE ALL RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ca1d876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_19629/718762210.py:16: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(clear_database)\n"
     ]
    }
   ],
   "source": [
    "# DELETE ALL RECORDS\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"neo4jkngbq\"\n",
    "database = \"neo4j\"\n",
    "\n",
    "def clear_database(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "try:\n",
    "    with GraphDatabase.driver(uri, auth=(username, password), database=database) as driver:\n",
    "        with driver.session() as session:\n",
    "            session.write_transaction(clear_database)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad6525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
