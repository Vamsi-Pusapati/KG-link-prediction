{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a174404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from neo4j import GraphDatabase\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed83202",
   "metadata": {},
   "source": [
    "## Load Json file to Create nodes and relations in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "60d2d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"neo4jkngbq\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def get_all_json_paths(folder_path):\n",
    "    \"\"\"\n",
    "    Retrieves all file paths ending with the '.json' extension within a folder and its subfolders using glob.\n",
    "\n",
    "    Args:\n",
    "      folder_path (str): The path to the folder where the search starts.\n",
    "\n",
    "    Returns:\n",
    "      list: A list containing absolute paths to all JSON files found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct a pattern to match all JSON files recursively\n",
    "    json_pattern = os.path.join(folder_path, \"**/*.json\")\n",
    "\n",
    "    # Use glob.glob to find all matching files\n",
    "    json_paths = glob.glob(json_pattern, recursive=True)\n",
    "\n",
    "    return json_paths\n",
    "\n",
    "\"\"\"\n",
    "    This methods loads the json data from the given file path and return the json data as dictionary\n",
    "\"\"\"\n",
    "def load_json_data_from_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = f.read()\n",
    "        json_data = json.loads(data)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c6363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cbd0a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_interface_node(tx, interface_data):\n",
    "    unique_id = interface_data.get(\"id\")\n",
    "    tx.run(\"MERGE (n:Interface {id:$unique_id}) SET n=$data\", data=interface_data, unique_id=unique_id)\n",
    "    \n",
    "def create_property_node(tx, property_data):\n",
    "    unique_id = property_data.get(\"id\")\n",
    "    tx.run(\"MERGE (n:Property {id:$unique_id}) SET n=$data\", data = property_data, unique_id=unique_id)\n",
    "    \n",
    "def create_nodes(tx,data):\n",
    "    interface_node_data = {}\n",
    "    interface_node_data[\"id\"] = data.get(\"@id\")\n",
    "    interface_node_data[\"type\"] = data.get(\"@type\")\n",
    "    interface_node_data[\"name\"] = data.get(\"displayName\")\n",
    "    interface_node_data[\"description\"] = data.get(\"description\")\n",
    "    interface_node_data[\"comment\"] = data.get(\"comment\")\n",
    "    \n",
    "    create_interface_node(tx, interface_node_data)\n",
    "    \n",
    "    if(None != data.get('extends')):\n",
    "        super_ids = data.get('extends')\n",
    "        interface_id = interface_node_data[\"id\"]\n",
    "        for super_id in super_ids:\n",
    "            tx.run(\"MERGE (n:Interface {id:$super_id}) ON CREATE SET n = {id:$super_id}\", super_id=super_id)\n",
    "            \n",
    "            tx.run(\"MATCH (parent:Interface {id:$super_id}), (child:Interface {id:$interface_id}) CREATE (parent)-[:has_child]->(child)\", super_id=super_id, interface_id=interface_id)\n",
    "\n",
    "    if(None != data.get('contents') or (len(data.get('contents'))>0)):\n",
    "        for content in data.get('contents'):\n",
    "            if(\"Property\" == content.get(\"@type\")):\n",
    "                property_node_data = {}\n",
    "                property_node_data['id'] = content.get('name')\n",
    "                property_node_data['name'] = content.get('name')\n",
    "                property_node_data['type'] = content.get('@type')\n",
    "                property_node_data['comment'] = content.get('comment')\n",
    "                if(isinstance(content.get('schema'), dict)):\n",
    "                    property_node_data['schema'] = \"enum\"\n",
    "                else:\n",
    "                    property_node_data['schema'] = content.get('schema')\n",
    "                \n",
    "                create_property_node(tx, property_node_data)\n",
    "                \n",
    "                interface_id = interface_node_data[\"id\"]\n",
    "                property_id = property_node_data['id']\n",
    "                \n",
    "                #query = \"\"\" MATCH (interface:Interface {{id:$interface_id})\n",
    "                 #           MATCH (property:Property {{id:$property_id}})\n",
    "                  #          CREATE (interface)-[:has_property]->(property)\n",
    "                   #     \"\"\"\n",
    "            \n",
    "                tx.run(\"MATCH (interface:Interface {id:$interface_id}), (property:Property {id:$property_id}) CREATE (interface)-[:has_property]->(property)\", interface_id=interface_id, property_id=property_id)\n",
    "                       \n",
    "            elif(\"Relationship\" == content.get(\"@type\")):\n",
    "                relation_node_data = {}\n",
    "                relation_node_data['id'] = content.get('target')\n",
    "                relation_node_data['name'] = content.get('displayName')\n",
    "                relation_node_data['comment'] = content.get('comment')\n",
    "                relation_node_data['@type'] = \"Interface\"\n",
    "                create_interface_node(tx, relation_node_data)\n",
    "                \n",
    "                \n",
    "                interface_id = interface_node_data[\"id\"]\n",
    "                relation_node_id = relation_node_data['id']\n",
    "                \n",
    "                tx.run(\"MATCH (interface:Interface {id:$interface_id}), (property:Interface {id:$relation_node_id}) CREATE (interface)-[:connected_to]->(property)\",interface_id=interface_id, relation_node_id=relation_node_id)\n",
    "              \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67aa599",
   "metadata": {},
   "source": [
    "# Load the Digital Twin Ontology to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85391c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/3357173862.py:8: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(create_nodes, data)\n",
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/3357173862.py:7: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session() as session:\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./Ontology\" \n",
    "json_file_paths = get_all_json_paths(folder_path)\n",
    "\n",
    "for each_json in json_file_paths:\n",
    "    data = load_json_data_from_file(each_json)\n",
    "\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(create_nodes, data)\n",
    "        \n",
    "    driver.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86574ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80efe6ce",
   "metadata": {},
   "source": [
    "# Create Node Text Csv for a given graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d6033af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Cypher query to retrive all nodes in interface and its corresponding connected nodes that have\n",
    "    either has_child, or connected_to relation\n",
    "\"\"\"\n",
    "\n",
    "def get_connected_nodes_and_relations(tx):\n",
    "    results = []\n",
    "    interface_label = \"Interface\"\n",
    "    rel_types=(\"has_child\",\"connected_to\")\n",
    "\n",
    "    cursor = tx.run(\"\"\"\n",
    "      MATCH (n:Interface)\n",
    "      WITH n, n.id AS id, n.comment as comment,n.name as name, n.description as description, n.type as type \n",
    "      OPTIONAL MATCH (n)-[r:has_child|connected_to]->(connected)\n",
    "      RETURN n, collect(DISTINCT {node: connected, rel_type: type(r)}) AS connectedInfo\n",
    "    \"\"\")\n",
    "\n",
    "    for record in cursor:\n",
    "\n",
    "        node = record[\"n\"]\n",
    "\n",
    "        connected_info = record[\"connectedInfo\"]\n",
    "\n",
    "        results.append({\"node\": node, \"connectedInfo\": connected_info})\n",
    "\n",
    "    return results\n",
    "#check if the data start with Adapted from CIM this is unwanted data so we do not want to embed them \n",
    "def is_unwanted_data(data, start_with = \"Adapted from CIM\"):\n",
    "    if(data.startswith(start_with)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\"\"\"\n",
    "    This method will return the textual format of nodes \n",
    "    the format is as bellow\n",
    "    node.name(either node.comment (or) node.description) \n",
    "\"\"\"\n",
    "def get_node_text_format(node_properties, node_dict):\n",
    "\n",
    "    if(None != node_dict.get(node_properties.get('id'))):\n",
    "        \n",
    "        return node_dict.get(node_properties.get('id'))\n",
    "    else:\n",
    "        text_to_embed = \"\"\n",
    "        if(node_properties.get('name')):\n",
    "            text_to_embed+=node_properties.get('name')\n",
    "        if(node_properties.get('comment') and not is_unwanted_data(node_properties.get('comment'))):\n",
    "            comment_to_add = node_properties.get('comment')\n",
    "            text_to_embed+=  \"(\" + comment_to_add + \")\"\n",
    "        if(node_properties.get('description') and not is_unwanted_data(node_properties.get('description'))):\n",
    "            comment_to_add = node_properties.get('description')\n",
    "            text_to_embed+=  \"(\" + comment_to_add + \")\"\n",
    "        node_dict[node_properties.get('id')] = text_to_embed\n",
    "        return text_to_embed\n",
    "\n",
    "\"\"\"\n",
    "    This method will retun the Interface node id, and the related text that need to be embeded \n",
    "    for the text data we are getting the node and its connected node information\n",
    "\"\"\"\n",
    "def get_nodes_and_text_to_embed():\n",
    "    # this stores the node and connection information fro the neo4j database\n",
    "    node_list = []\n",
    "    with driver.session() as session:\n",
    "        node_list = session.write_transaction(get_connected_nodes_and_relations)\n",
    "        driver.close() \n",
    "\n",
    "    #this is the attribute that we will return that store list of {id:, text_to_embed:}\n",
    "    nodes_to_embed = []\n",
    "    \n",
    "    # this is used to have node related information had {key: node_id, value: get_node_text_format return value}\n",
    "    node_dict = {}\n",
    "    \n",
    "    for data in node_list:\n",
    "        #this gets the node details form the result\n",
    "        node = data[\"node\"]\n",
    "        #this stores both the connection nodes as its relationship with the Node as a list\n",
    "        connected_info = data[\"connectedInfo\"]\n",
    "        #get node properties like id, name, comment, description as a dictionary\n",
    "        node_properties = node._properties\n",
    "        \n",
    "        #this will store {id:, text_to_embed:} ans will be appended to nodes_to_embed\n",
    "        node_details = {}\n",
    "\n",
    "        node_details['id'] =node_properties.get('id')\n",
    "\n",
    "        #text_to_embed store the textual format od the node\n",
    "        text_to_embed = get_node_text_format(node_properties, node_dict)\n",
    "\n",
    "\n",
    "        if (connected_info):\n",
    "            #seperating child relation and the connected to relation\n",
    "            has_child = []\n",
    "            connected_to = []\n",
    "            for info in connected_info:\n",
    "                \n",
    "                if(None != info[\"node\"] and None != info[\"rel_type\"]):\n",
    "\n",
    "                    connected_node = info[\"node\"]\n",
    "                    rel_type = info[\"rel_type\"]\n",
    "                    \n",
    "                    #get text information for each connection node\n",
    "                    node_text = get_node_text_format(connected_node,node_dict)\n",
    "\n",
    "                    if(rel_type == \"has_child\" and node_text):\n",
    "                        has_child.append(node_text)\n",
    "                        \n",
    "                    elif(rel_type == \"connected_to\" and node_text):\n",
    "                        connected_to.append(node_text)\n",
    "\n",
    "            if(len(has_child)>0):\n",
    "                child_text = \", \".join(has_child)\n",
    "                text_to_embed += \" has the following children:\" + child_text\n",
    "            if(len(connected_to)>0):\n",
    "                connected_text = \", \".join(connected_to)\n",
    "                text_to_embed += \", is connected to:\" + connected_text\n",
    "\n",
    "            node_details['text_to_embed'] = text_to_embed \n",
    "            nodes_to_embed.append(node_details)           \n",
    "\n",
    "        else:\n",
    "            print(\"No connected nodes found.\")\n",
    "    return nodes_to_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6a8895ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/2335851549.py:56: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session() as session:\n",
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/2335851549.py:57: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  node_list = session.write_transaction(get_connected_nodes_and_relations)\n"
     ]
    }
   ],
   "source": [
    "#Run once to generate the csv file\n",
    "import pandas as pd\n",
    "nodes_to_embed_dict = get_nodes_and_text_to_embed()\n",
    "if(nodes_to_embed_dict):\n",
    "    df = pd.DataFrame(nodes_to_embed_dict)\n",
    "    df.to_csv(\"./node_texts.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82168558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04f84682",
   "metadata": {},
   "source": [
    "# Load Node Embeddings to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1de397f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"neo4jkngbq\"\n",
    "database = \"neo4j\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "def get_dicts_from_csv_file(file_name):\n",
    "    if not os.path.isfile(file_name):\n",
    "        print(f\"File '{file_name}' does not exist.\")\n",
    "        return None\n",
    "    file_path = \"./\"+file_name\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    return df.to_dict(\"records\")\n",
    "\n",
    "def set_embedding_to_node(tx, node_data):\n",
    "    nodeId = node_data.get('id')\n",
    "    embeddings = node_data.get('embeddings')\n",
    "    tx.run(\"MATCH (node:Interface {id: $nodeId}) SET node.embeddings = $embeddings RETURN node\",nodeId=nodeId,embeddings=embeddings)\n",
    "    \n",
    "\n",
    "def load_embeddings_from_file_to_neo4j(file_name):\n",
    "    node_emb_dict_list = get_dicts_from_csv_file(file_name)\n",
    "    if(None != node_emb_dict_list):\n",
    "        for node_dict in node_emb_dict_list:\n",
    "            if(None != node_dict.get(\"embeddings\") and not pd.isna(node_dict.get(\"embeddings\"))):\n",
    "                try:\n",
    "                    with driver.session() as session:\n",
    "                        session.write_transaction(set_embedding_to_node, node_dict)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "        driver.close() \n",
    "    print(\"Loaded successsfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a2eb9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/3590113348.py:31: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(set_embedding_to_node, node_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successsfully\n"
     ]
    }
   ],
   "source": [
    "load_embeddings_from_file_to_neo4j(\"node_texts_with_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e0219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e5def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc36c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a604deee",
   "metadata": {},
   "source": [
    "# *DELETE ALL RECORDS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "441ca80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/8ywy_8nd2z716q65sc27_81r0000gn/T/ipykernel_36634/3682526915.py:16: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(clear_database)\n"
     ]
    }
   ],
   "source": [
    "# DELETE ALL RECORDS\n",
    "#Do not run this until experiment is compelete\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"neo4jkngbq\"\n",
    "database = \"neo4j\"\n",
    "\n",
    "def clear_database(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "try:\n",
    "    with GraphDatabase.driver(uri, auth=(username, password), database=database) as driver:\n",
    "        with driver.session() as session:\n",
    "            session.write_transaction(clear_database)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62a520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
